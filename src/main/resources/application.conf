redis {
  host = ${?REDIS_HOST}
  port = 6379
  use_ssl = false
  use_ssl = ${?REDIS_USE_SSL}
  auth_token = ""
  auth_token = ${?REDIS_AUTH_TOKEN}
}

timeseries {
  s3-base-url = ${?CLOUDFRONT_URL}
  s3-host = ${?CLOUDFRONT_HOST}

  parallelism = 8
  parallelism = ${?PARALLELISM}

  throttle {
    items = ${?TIMESERIES_THROTTLE_ITEMS}
    period = ${?TIMESERIES_THROTTLE_PERIOD_SECONDS}
  }

  bind-port = ${?TIMESERIES_PORT}

  bind-address = "0.0.0.0"
  bind-address = ${?TIMESERIES_ADDRESS}

  query-limit = 100000
  query-limit = ${?QUERY_LIMIT}

  # some other timeout is kicking in at 60 seconds, which prevents us from shutting down properly
  idle-timeout = 2m
  idle-timeout = ${?IDLE_TIMEOUT}

  default-gap-threshold = 2.0
  default-gap-threshold = ${?DEFAULT_GAP_THRESHOLD}

  request-queue-size = 100
  request-queue-size = ${?REQUEST_QUEUE_SIZE}

   # when the requested (pixelWidth * send_spike_threshold) < spikeDuration, we will send the spike data
  send-spike-threshold = 10
  send-spike-threshold = ${?SEND_SPIKE_THRESHOLD}
}

custom-io-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher

  ///type =PinnedDispatcher
  # What kind of ExecutionService to use
  executor = "thread-pool-executor"

  thread-pool-executor {

    # minimum number of threads to cap factor-based core number to
    core-pool-size-min = 2

    # No of core threads ... ceil(available processors * factor)
    core-pool-size-factor = 8.0

    # maximum number of threads to cap factor-based number to
    core-pool-size-max = 10
  }

  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 100
}

akka {
  loglevel = ${?AKKA_LOG_LEVEL}

  stream = {
    debug-logging = ${?AKKA_STREAM_DEBUG_LOGGING}
  }
}

postgresTS {
  db {
    default {
      url="jdbc:postgresql://"${?DATA_POSTGRES_HOST}":"${?DATA_POSTGRES_PORT}"/"${?DATA_POSTGRES_DATABASE}"?ssl=true&sslmode=verify-ca"
      user=${?DATA_POSTGRES_USER}
      password=${?DATA_POSTGRES_PASSWORD}
    }
  }
}

# TODO: These configuration parameters are required due to the
# dependency on pennsieve-core and Secure/Insecure containers. When we
# move off of that model (and hit the api endpoints instead of going
# directly to the DB to get channel information), remove this.
pennsieve {
  session_timeout = 28800    //8 hours
  temp_session_timeout = 600
  api_session_timeout = 7200 // 2 hours

  storage {
    redisDBIndex = 3
  }

}

jwt-key = ${?JWT_KEY}

data {
  postgres {
    database="postgres"
    database=${?DATA_POSTGRES_DATABASE}
    host="postgres"
    host=${?DATA_POSTGRES_HOST}
    password="password"
    password=${?DATA_POSTGRES_PASSWORD}
    port=5432
    port=${?DATA_POSTGRES_PORT}
    user="postgres"
    user=${?DATA_POSTGRES_USER}
  }
}

postgres {
  database="postgres"
  database=${?POSTGRES_DATABASE}
  host="postgres"
  host=${?POSTGRES_HOST}
  password="password"
  password=${?POSTGRES_PASSWORD}
  port=5432
  port=${?POSTGRES_PORT}
  user="postgres"
  user=${?POSTGRES_USER}
}
